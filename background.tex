\subsection{What are mixed reality ethics?}\label{sec:ethics}

Computer ethics is the analysis of the nature and social impact of computer technology and the corresponding formulation and justification of policies for the ethical use of such technology~\cite{moor1985computer}. This then implies that MR ethics is the analysis of the social impact of MR technology. A key ingredient in MR ethics is privacy---MR offers new opportunities to violate individuals' privacy expectations, as well as new ethical considerations of the consequences. Cohen argues that privacy and freedom from surveillance are foundational to individual's expression and participation in civilization~\cite{cohen2012privacy}. The current personalization trend, enabled by extensive tracking and fingerprinting, means that information about us then shapes the information we see. This leads two individuals to have drastically different experiences of the same environment. For example, one individual sees ads for high-paying jobs, while another on the same platform only sees ads for low-paying jobs. The consequences of this are that the second individual, by virtue of personalization, has no opportunity to apply for the better jobs. In a more ethical world, both individuals would see a more similar mix of advertisements.

From an ethical perspective, the \emph{immersive web} has a number of advantages over a solely app-based ecosystem. Unlike apps, there are no inherent restrictions on who can develop or access web resources. It is also intended to be cross-platform, allowing users with a \$300 MR device to have a similar experience to those with a \$3000 device. Perhaps most importantly, it allows web browsers to act as a trusted intermediary for device resource requests. Instead of a native app running in the background with access to information like orientation data, the webpage needs to request this through the browser, which could reject inappropriate requests.

However, the \emph{immersive web} will coexist with native apps, which may have different purposes and capabilities. We should not focus solely on creating a better web, but also on using ethical principles to guide the development of all MR applications---particularly since native apps often have more direct access to device internals.

Tech companies have embraced the mantras of `ask for forgiveness not permission' and `move fast and break things' to the detriment of individuals' privacy, security, and safety. Instead of thoughtfully approaching difficult problems and considering how we can prevent abuse, we sell applications that actively aid abusers~\cite{dell}. Instead of designing systems to empower and protect users, we create environments that foster harassment without clear or sufficient accountability mechanisms~\cite{dreyfuss}. Instead of debiasing algorithms and training data, we build self-driving cars that are more likely to hit dark-skinned people~\cite{wilson2019predictive}. This creates an unethical world, where technology determines that different users have different consequences, often based on intrinsic characteristics.

By building technology that violates users' privacy and denies them agency, we are creating a dystopian future. Mixed reality, with its ability to combine virtual and physical elements, is a powerful mechanism for distorting our perspectives.  In 1987, Simitis argued that large scale data collection is ``the ideal means to adapt an individual to a predetermined, standardized behavior that aims at the highest possible degree of compliance with the model patient, consumer, taxpayer, employee, or citizen''~\cite{simitis}. If we extend this reasoning to the scale of data collection today and then consider incorporating MR-derived data, it is clear that we need to embrace ethical principles before it is too late. The goal of big data and technology should not be to render individuals more predictable, but rather to better understand their motivations and actions.

Generally, the ethics of emerging technologies are focused on ethical assessments of research and innovation. Mixed reality ethics occupies a space that encompasses emerging tech ethics, healthcare ethics and product ethics. Healthcare ethics are included due to the large amount of health-related and biometric data that can be collected or inferred by MR devices; an example of product ethics in MR would be creating devices that can be worn by anyone (regardless of head shape and hair style or texture). MR technology is beyond emerging, but not quite entrenched. We are still in a position to intervene in the development process, instead of attempting to retrofit ethical decisions into an established design.

MR ethics are unique because the data required to create the experiences is also inherently a privacy threat. An MR experience must have information about the user's motion, as well as the space surrounding the user. All of this data allows non-obvious inferences that will be discussed in \autoref{sec:data}.


\subsection{Mixed reality data processing}\label{sec:data}

How are immersive ethics any different from other technologies? Immersive technologies, whether augmented or virtual, affect our physical bodies in ways that non-immersive technologies do not. Head-mounted displays (HMDs) overlay and mix virtual elements on our senses, changing our perceptions of ourselves and our surroundings. Sometimes, this can even result in `cybersickness.'

A key problem in MR is that the data required to provide experiences is also inherently a privacy threat. For example, while it is reasonable for users to choose to cover their cameras on their computers or phones to protect their privacy, this simply is not an option on MR devices, which rely heavily on data derived from cameras.

What about non-immersive, hand-held, AR? While it does not have the same physical effects on users, it shares many of the same data privacy concerns. MR experiences continuously collect and process environmental data in near-real time. In this case, the data available is much more extensive than even the intrusive data collection we have become accustomed to currently.

Spatial computing and immersive experiences expose, by necessity, information that poses a threat to privacy. To enable these technologies, we rely on many extended duration sensors. These sensors fall into three categories: biometric, orientation, and environmental.

\subsection{Biometric data}\label{sec:biometrics}
A wide range of what we call biometrically-derived data (BDD) can be collected by head-mounted displays (HMDs), some of which are non-obvious to users. In addition to eye-tracking data, we can collect information on users' gait, height, and physical or emotional reactions.

BDD is distinguished from biometrics like fingerprint scans, retina scans, and facial scans, which can be obtained by a single scan, while BDD refers to data obtained from tracking over a period of time. Like biometrics, BDD is information that is tied to our intrinsic characteristics. Unlike biometrics, BDD may evolve over time, revealing inferences into individual's age (e.g., gait).

Biometric information presents particularly difficult problems. Firstly, once exposed, there is no way to retrieve or change it. Even worse, it provides methods for fingerprinting users by their physical attributes, not just their online behaviors. Biometrics also provide insight into involuntary nonverbal reactions~\cite{bailenson2018protecting}. Pupil dilation and skin temperature can indicate a user's sexual attraction or orientation~\cite{bolmont2014love}. Gaze tracking can expose basic user information such as age, race, and gender, as well as details of medical conditions like autism or anxiety disorders~\cite{liebling2014privacy}. Innocuous data like facial movements during a task can classify people as high or low performers~\cite{jabon2011automatically}.

Further research will likely expand the set of inferences and fingerprinting methods enabled by BDD.

\subsection{World data}

Particularly for AR applications, we need to incorporate world data to the virtual model. Suppose a user wishes to place a virtual dinosaur on a table in front of them---first, the application must know that there is a table in front of the user. World sensing also refers to properly sensing ambient light.

While data about the physical world is collected using cameras, devices do not have to provide all information to the application. Instead of providing full camera access, platforms can provide limited hit testing (determining whether a user-controlled cursor intersects an element in the scene) or a world mesh (an abstract representation of all planes and objects in the scene as a mesh, removing all RGB camera data).

We need to identify ways to incentivize the principle of least privilege---it is easy to provide full camera access to applications and let them figure out what they want to use. However, that should not be the default option. World meshes and hit testing provide sufficient spatial data for many applications without also transmitting details like text.

\subsection{Orientation data}

MR devices use accelerometers, magnetometers, and gyroscopes to orient themselves in the physical world. Because of permission fatigue, devices do not ask permission for all sensor accesses. Instead, they sort sensors into two categories: dangerous and not. `Dangerous' sensors include microphones, cameras, and GPS, while orientation sensors are considered `not dangerous.'

However, it turns out that `not dangerous' sensors also pose serious concerns to user privacy. For example, we can use the accelerometer or ambient light sensor of a cellphone to extract the user's screen lock pin~\cite{aviv2012practicality, spreitzer2018systematic}. The interactions between sensors pose a threat to our existing security models. it is difficult to anticipate the potential side channel attacks that existing sensors pose, let alone predict how additional sensors may create novel threat vectors.

Permissions have already become too complex to easily communicate to users what data is gathered and the potential consequences of its use or misuse.


